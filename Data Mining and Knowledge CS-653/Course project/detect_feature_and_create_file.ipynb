{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import for data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from labelscount import mergeoverlaylabel, boxing\n",
    "import labelscount\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from math import cos, pi\n",
    "import json\n",
    "\n",
    "import googleapi\n",
    "\n",
    "import io\n",
    "\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn import metrics\n",
    "# from sklearn import decomposition\n",
    "\n",
    "# import importlib\n",
    "# # import foo #import the module here, so that it can be reloaded.\n",
    "# importlib.reload(labelscount)\n",
    "# # import sys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_detection.darkflow.net.build import TFNet\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"model\": \"./feature_detection/cfg/road_yolo.cfg\",\n",
    "           \"config\": \"./feature_detection/cfg\",\n",
    "           \"load\": -1,\n",
    "           \"batch\" : 4,\n",
    "           \"labels\": \"./feature_detection/labels.txt\",\n",
    "           'backup': \"./feature_detection/model\",\n",
    "           \"gpu\": 0.0}\n",
    "\n",
    "light_windows_tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_options = {\"model\": \"./feature_detection/cfg/yolo.cfg\", \n",
    "           \"load\": \"./feature_detection/bin/yolo.weights\",\n",
    "           \"config\": \"./feature_detection/cfg\",\n",
    "           \"batch\" : 4,\n",
    "           \"labels\": \"./feature_detection/labels.txt\",\n",
    "           \"gpu\": 0.0}\n",
    "\n",
    "# options\n",
    "car_tfnet = TFNet(car_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load crime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_path = './dataset/incidents-100k.csv'\n",
    "# crime_cols =[\"id\",'type','lampdist','lon','lat'] #Columns which need\n",
    "crime_cols =[\"id\",\"year\",'type','lampdist','lon','lat'] #Columns which need\n",
    "# crime_sample =100\n",
    "\n",
    "light_path = './dataset/streetlight_locations_datasd.csv'\n",
    "light_cols =['latitude','longitude'] #Columns which need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crime_df = pd.read_csv(crime_path,usecols =crime_cols)\n",
    "robbery_df = all_crime_df.loc[(all_crime_df['type'].isin([\"ROBBERY\"])) & (all_crime_df['year']>2002) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load street lights data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_light_df = pd.read_csv(light_path,usecols =light_cols).dropna()\n",
    "all_light_df.sort_values(by=light_cols, inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab data and create a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset/my_data.csv'\n",
    "dataset_cols =[\"id\",'year','windows','car','lights','gas',\"convience\",\"sdpd\",'lampdist','lat','lon','crime']\n",
    "dataset = pd.DataFrame(columns = dataset_cols);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "row_count = 0\n",
    "\n",
    "dataset = pd.DataFrame(columns = dataset_cols);\n",
    "for index, row in robbery_df.iterrows():\n",
    "#     print(row)\n",
    "    if row_count <= 200:\n",
    "        row_count +=1\n",
    "        continue\n",
    "    \n",
    "    dataset.loc[count] = {\"id\":str(row[\"year\"])+\"_\"+str(index),'year':row[\"year\"],'car':0,'windows': 0, 'lights':0, 'gas':0, 'convience':0, \\\n",
    "                          'sdpd':0, 'lampdist':row['lampdist']/100, 'lon':row['lon'], \\\n",
    "                          'lat':row['lat'], 'crime':row['type']}\n",
    "    count +=1\n",
    "#     if count ==30:\n",
    "#     if count ==20:\n",
    "#         break\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count numbers of lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areacalculate(lat,lon,offset):\n",
    "\n",
    "    # Earthâ€™s radius, sphere\n",
    "    R=6378137\n",
    "\n",
    "#     # offsets in meters\n",
    "    dn = offset\n",
    "    de = offset\n",
    "\n",
    "    # Coordinate offsets in radians\n",
    "    dLat = dn/R\n",
    "    dLon = de/(R*cos(pi*lat/180))\n",
    "\n",
    "    # OffsetPosition, decimal degrees\n",
    "    latO = lat + dLat * 180/pi\n",
    "    lonO = lon + dLon * 180/pi\n",
    "    return latO,lonO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberOflights(point_lat,point_lon,distance):\n",
    "    \n",
    "    lat,lon = areacalculate(point_lat,point_lon,distance)\n",
    "#     print(str(lat)+\",\"+(str(lon)))\n",
    "    top_right = [lon,lat]\n",
    "\n",
    "    lat,lon = areacalculate(point_lat,point_lon,-distance)\n",
    "#     print(str(lat)+\",\"+(str(lon)))\n",
    "    bottom_left = [lon,lat]\n",
    "\n",
    "    lights = all_light_df.loc[(all_light_df['longitude'] <= top_right[0] )& (all_light_df['longitude'] >= bottom_left[0] )\\\n",
    "                     & ( all_light_df['latitude'] >=  bottom_left[1] ) & (all_light_df['latitude'] <= top_right[1]) ]\n",
    "#     print(lights)\n",
    "    return len(lights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(dataset)):\n",
    "    number = numberOflights(dataset.at[index,\"lat\"],dataset.at[index,\"lon\"],distance=20)\n",
    "    dataset.at[index,\"lights\"]  =number\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab street views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabAndsavestreetview(filepath,location,loc_id):\n",
    "    pic_path = filepath + loc_id+ '_0.jpg'\n",
    "    meta_request = googleapi.grabstreetview(location,120,10,0)\n",
    "    f = open(pic_path, 'wb') \n",
    "    f.write(meta_request.content) \n",
    "    f.close() \n",
    "    \n",
    "    pic_path = filepath + loc_id+ '_1.jpg'\n",
    "    meta_request = googleapi.grabstreetview(location,120,10,90)\n",
    "    f = open(pic_path, 'wb') \n",
    "    f.write(meta_request.content) \n",
    "    f.close() \n",
    "    \n",
    "    pic_path = filepath + loc_id+ '_2.jpg'\n",
    "    meta_request = googleapi.grabstreetview(location,120,10,180)\n",
    "    f = open(pic_path, 'wb') \n",
    "    f.write(meta_request.content) \n",
    "    f.close() \n",
    "    \n",
    "    pic_path = filepath + loc_id+ '_3.jpg'\n",
    "    meta_request = googleapi.grabstreetview(location,120,10,260)\n",
    "    f = open(pic_path, 'wb') \n",
    "    f.write(meta_request.content) \n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the images by google API\n",
    "streetview_path = './dataset/street_view/'\n",
    "for index in range(len(dataset)):\n",
    "    location = str(dataset.at[index,\"lat\"])+\",\"+str(dataset.at[index,\"lon\"])\n",
    "    grabAndsavestreetview(streetview_path, location, dataset.at[index,\"id\"])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelscount\n",
    "\n",
    "import importlib\n",
    "# import foo #import the module here, so that it can be reloaded.\n",
    "importlib.reload(labelscount)\n",
    "# import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan pictures\n",
    "streetview_path = './dataset/street_view/'\n",
    "pic_num = 4;\n",
    "\n",
    "for index in range(len(dataset)):\n",
    "#     location = str(dataset.at[index,\"lat\"])+\",\"+str(dataset.at[index,\"lon\"])\n",
    "    for num in range(pic_num):\n",
    "        picture_name = dataset.at[index,\"id\"]+\"_\" + str(num) + \".jpg\"\n",
    "        street_img = cv2.imread(streetview_path+picture_name)\n",
    "        street_img = cv2.cvtColor(street_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        scan_results = light_windows_tfnet.return_predict(street_img)\n",
    "        window_result = [aresult for aresult in scan_results if aresult['label'] == \"window\" and aresult['confidence'] > 0.1]\n",
    "        final_result = labelscount.mergeoverlaylabel(window_result)\n",
    "        dataset.at[index,\"windows\"]  =len(final_result)\n",
    "        \n",
    "        scan_results = car_tfnet.return_predict(street_img)\n",
    "        car_result = [aresult for aresult in scan_results if aresult['label'] == \"car\" and aresult['confidence'] > 0.1]\n",
    "        final_result = labelscount.mergeoverlaylabel(car_result)\n",
    "        dataset.at[index,\"car\"]  =len(final_result)\n",
    "    \n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(dataset)):\n",
    "    location = str(dataset.at[index,\"lat\"])+\",\"+str(dataset.at[index,\"lon\"])\n",
    "    \n",
    "    gas_request = googleapi.searchnearby(location,100,\"gas_station\")\n",
    "    parsed = json.loads(gas_request.content)\n",
    "    dataset.at[index,\"gas\"]  =len(parsed[\"results\"])\n",
    "\n",
    "    cs_request = googleapi.searchnearby(location,100,\"convenience_store\")\n",
    "    parsed = json.loads(cs_request.content)\n",
    "    dataset.at[index,\"convience\"]  =len(parsed[\"results\"])\n",
    "\n",
    "    \n",
    "    sdpd_request = googleapi.searchnearby(location,500,\"police\")\n",
    "    parsed = json.loads(sdpd_request.content)\n",
    "    dataset.at[index,\"sdpd\"]  =len(parsed[\"results\"])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1: Types supported in place search\n",
    "You can use the following values in the types filter for place searches.\n",
    "accounting\n",
    "airport\n",
    "amusement_park\n",
    "aquarium\n",
    "art_gallery\n",
    "atm\n",
    "bakery\n",
    "bank\n",
    "bar\n",
    "beauty_salon\n",
    "bicycle_store\n",
    "book_store\n",
    "bowling_alley\n",
    "bus_station\n",
    "cafe\n",
    "campground\n",
    "car_dealer\n",
    "car_rental\n",
    "car_repair\n",
    "car_wash\n",
    "casino\n",
    "cemetery\n",
    "church\n",
    "city_hall\n",
    "clothing_store\n",
    "convenience_store\n",
    "courthouse\n",
    "dentist\n",
    "department_store\n",
    "doctor\n",
    "electrician\n",
    "electronics_store\n",
    "embassy\n",
    "fire_station\n",
    "florist\n",
    "funeral_home\n",
    "furniture_store\n",
    "gas_station\n",
    "gym\n",
    "hair_care\n",
    "hardware_store\n",
    "hindu_temple\n",
    "home_goods_store\n",
    "hospital\n",
    "insurance_agency\n",
    "jewelry_store\n",
    "laundry\n",
    "lawyer\n",
    "library\n",
    "liquor_store\n",
    "local_government_office\n",
    "locksmith\n",
    "lodging\n",
    "meal_delivery\n",
    "meal_takeaway\n",
    "mosque\n",
    "movie_rental\n",
    "movie_theater\n",
    "moving_company\n",
    "museum\n",
    "night_club\n",
    "painter\n",
    "park\n",
    "parking\n",
    "pet_store\n",
    "pharmacy\n",
    "physiotherapist\n",
    "plumber\n",
    "police\n",
    "post_office\n",
    "real_estate_agency\n",
    "restaurant\n",
    "roofing_contractor\n",
    "rv_park\n",
    "school\n",
    "shoe_store\n",
    "shopping_mall\n",
    "spa\n",
    "stadium\n",
    "storage\n",
    "store\n",
    "subway_station\n",
    "supermarket\n",
    "synagogue\n",
    "taxi_stand\n",
    "train_station\n",
    "transit_station\n",
    "travel_agency\n",
    "veterinary_care\n",
    "zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization on Goole Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps.configure(api_key='AIzaSyCXFae-0HuYIW0Pqph0LiBYiSu90nSIHcE') # Fill in with your API key\n",
    "\n",
    "crime_loc =[]\n",
    "for index in range(len(dataset)):\n",
    "    crime_loc.append((dataset.at[index,\"lat\"], dataset.at[index,\"lon\"]))\n",
    "    #     crime_loc = str(dataset.at[index,\"lat\"])+\",\"+str(dataset.at[index,\"lon\"])\n",
    "\n",
    "    \n",
    "fig = gmaps.figure(map_type='ROADMAP')\n",
    "# generate some (latitude, longitude) pairs locations = [(51.5, 0.1), (51.7, 0.2), (51.4, -0.2), (51.49, 0.1)]\n",
    "heatmap_layer = gmaps.heatmap_layer(crime_loc)\n",
    "fig.add_layer(heatmap_layer) \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from ipywidgets.embed import embed_minimal_html\n",
    "# embed_minimal_html('export.html', views=[fig])\n",
    "fig._map.layout.width = '500px' # Supports any CSS length\n",
    "fig._map.layout.height = '1500px' # Supports any CSS length\n",
    "fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gmaps \n",
    "# import gmaps.datasets\n",
    "# gmaps.configure(api_key='AIzaSyCXFae-0HuYIW0Pqph0LiBYiSu90nSIHcE') # Fill in with your API key\n",
    "# df = gmaps.datasets.load_dataset_as_df('starbucks_kfc_uk')\n",
    "# starbucks_df = df[df['chain_name'] == 'starbucks'] \n",
    "# starbucks_df = starbucks_df[['latitude', 'longitude']]\n",
    "# starbucks_layer = gmaps.symbol_layer( starbucks_df, fill_color='green', stroke_color='green', scale=2 ) \n",
    "# fig = gmaps.figure() \n",
    "# fig.add_layer(starbucks_layer) \n",
    "# fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crime_loc =[]\n",
    "for index in range(len(dataset)):\n",
    "    crime_loc.append((dataset.at[index,\"lat\"], dataset.at[index,\"lon\"]))\n",
    "\n",
    "gmaps.configure(api_key='AIzaSyCXFae-0HuYIW0Pqph0LiBYiSu90nSIHcE') # Fill in with your API key\n",
    "\n",
    "sym_fig = gmaps.figure()  \n",
    "symbol_layer = gmaps.symbol_layer(crime_loc,fill_color='green', stroke_color='green', scale=2)\n",
    "sym_fig.add_layer(symbol_layer) \n",
    "sym_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
